{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import json\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "\n",
    "# third party\n",
    "import pandas as pd\n",
    "from rbo.rbo import rbo\n",
    "\n",
    "# local\n",
    "from src.config_ import PATHS, LEXISNEXIS\n",
    "from src.doc_analysis import most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load total and unique token and entity counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'total': 'dct_total_tokens_and_entities.pkl',\n",
    "    'unique': 'dct_unique_tokens_and_entities.pkl',\n",
    "}\n",
    "\n",
    "d = dict()\n",
    "for key, file in files.items():\n",
    "    with open(PATHS.results / file, 'rb') as f:\n",
    "        d[key] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the alts from the data and add their count to the main key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATHS.parameters / 'alts_countries.json', 'r', encoding='utf8') as f:\n",
    "    alts_countries = json.load(f)\n",
    "\n",
    "for count_type in d:\n",
    "    for batch in LEXISNEXIS.batches:\n",
    "        for country in alts_countries:\n",
    "            for alt in alts_countries[country]:\n",
    "                n = d[count_type][batch]['countries'][alt]\n",
    "                del d[count_type][batch]['countries'][alt]\n",
    "                d[count_type][batch]['countries'][country] += n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique entities per type and newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_entities = ['countries', 'places', 'places_uk', 'places_nl', 'places_fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "for ent in geo_entities:\n",
    "    for batch in d['total']:\n",
    "        data.append([ent, batch, len(d['total'][batch][ent])])\n",
    "pd.DataFrame(data, columns=['geo_entity', 'source', 'count']).set_index(['geo_entity', 'source']).unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of occurrences per entity type and label\n",
    "Each occurrence is counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for ent in geo_entities:\n",
    "    df_ = most_common(d['total'], ent, n=12)\n",
    "    df_ = pd.concat([df_], keys=[ent], names=['entity_type'])\n",
    "    df = df.append(df_)\n",
    "df.update(df.xs('count', level=1, axis=1, drop_level=False).astype('Int64'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of occurrences per entity type and label\n",
    "Labels are only counted once per article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for ent in geo_entities:\n",
    "    df_ = most_common(d['unique'], ent, n=12)\n",
    "    df_ = pd.concat([df_], keys=[ent], names=['entity_type'])\n",
    "    df = df.append(df_)\n",
    "df.update(df.xs('count', level=1, axis=1, drop_level=False).astype('Int64'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare rankings between newspapers\n",
    "First compare between entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for ent in geo_entities:\n",
    "    rankings = df.xs(ent).xs('label', axis=1, level=1)\n",
    "    for combo in combinations(rankings.columns, 2):\n",
    "        data = rbo(rankings[combo[0]], rankings[combo[1]], 0.9)\n",
    "        s = pd.Series(data=data, name=(ent, combo))\n",
    "        if results.empty:\n",
    "            results = s.to_frame()\n",
    "        else:\n",
    "            results = results.join(s, how='outer')\n",
    "results = results.T\n",
    "results.index = pd.MultiIndex.from_tuples(results.index)\n",
    "results.index.names = ('geo_entity', 'comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['geo_entity', 'min'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compare when combining all counts into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "rankings = df.xs('label', axis=1, level=1)\n",
    "for combo in combinations(rankings.columns, 2):\n",
    "    ranking1 = df.xs(combo[0], axis=1).sort_values('count', ascending=False).label\n",
    "    ranking2 = df.xs(combo[1], axis=1).sort_values('count', ascending=False).label\n",
    "    data = rbo(ranking1, ranking2, 0.8)\n",
    "    s = pd.Series(data=data, name=combo)\n",
    "    if results.empty:\n",
    "        results = s.to_frame()\n",
    "    else:\n",
    "        results = results.join(s, how='outer')\n",
    "results = results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('min', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of lemma occurrences\n",
    "All occurrences are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common(d['total'], 'lemma', n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique lemma occurrences\n",
    "Lemma's are only counted once per article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common(d['unique'], 'lemma', n=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "place-extraction",
   "language": "python",
   "name": "place-extraction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
